\documentclass[11pt,twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage{balance}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{listings}
\geometry{margin=0.75in}

% Configure code listings
\lstset{
    basicstyle=\footnotesize\ttfamily,
    breaklines=true,
    frame=single,
    captionpos=b,
    numbers=left,
    numberstyle=\tiny,
    showstringspaces=false,
    language=C
}

% Define JavaScript-like language for listings
\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break, const, let, class, export, import, async, await},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

% Header and footer
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\scriptsize AWARE: Smart Caching for Emergency Flood Warnings}
\fancyhead[R]{\scriptsize \thepage}
\renewcommand{\headrulewidth}{0.4pt}

\title{\Large\textbf{Smart Caching and Offline Emergency Warning Systems for Flood Scenarios: AWARE EAS Framework}}

\author{
    \textbf{Charles Melvin}\textsuperscript{1}, \textbf{Prof. Nhat Rich Nguyen}\textsuperscript{2} \\
    \small\textsuperscript{1}Department of Computer Science, University of Virginia, Charlottesville, VA 22903 \\
    \small\texttt{\{jgm6jy, nn4pj\}@virginia.edu}
}

\date{\small Submitted: Not yet lol}

\begin{document}

\maketitle

\begin{abstract}
\noindent ABSTRACT NOT AVAILABLE YET
\end{abstract}

\noindent\textbf{Keywords:} 
Emergency Alert System, Flood Warning, Floodwatch, Offline Caching, 
Smart Cities, Disaster Management, Edge Computing, Dexie, 
Progressive Web Applications, Offline-First Applications, 
Delay-Tolerant Networking (DTN), Mesh Networking, 
Local-First Software, Service Workers, 
Disaster Communication, Crisis Informatics, 
Human-Centered Computing, Cognitive Load, 
Stress-Aware Design, Resilient Networking

\vspace{0.3cm}

\section{Introduction}

\subsection{Motivation}

Unlike prior approaches that primarily optimize for network throughput and latency, AWARE is motivated by the reality that flood response hinges equally on human factors. People under stress need alerts that are timely, but also clear, non-duplicative, and trustworthy. Thus, our evaluation considers not only delivery speed and coverage, but also cognitive load and user trust—metrics such as redundancy index, actionability-first ratio, and timeliness consistency—so that system performance can be assessed in terms of both efficiency and psychological impact.


\subsection{Problem Statement}
The primary challenges in flood emergency warning systems include:

\begin{itemize}
    \item \textbf{Connectivity fragility.} Floods often cause localized outages of cellular towers, backhaul links, and power, leaving users disconnected exactly when alerts are most critical.
    \item \textbf{Overload and congestion.} Spikes in simultaneous alert delivery can saturate networks, increasing latency and loss, especially in dense urban sectors.
    \item \textbf{Staleness and duplication.} Existing broadcast channels may deliver multiple redundant alerts or stale updates, eroding clarity and user trust.
    \item \textbf{Limited offline capability.} Current alerting systems assume continuous connectivity; without local caches, users cannot access critical instructions once offline.
    \item \textbf{Lack of human-centered metrics.} System performance is typically measured only in terms of delivery speed and coverage, with little attention to cognitive load, redundancy, or actionability under stress.
\end{itemize}


\subsection{Contributions}
This paper presents the following key contributions:
\begin{enumerate}
\item DUMMY
\end{enumerate}

\section{Related Work}

\subsection{Emergency Alert Systems}
Modern public warning in the U.S. centers on FEMA’s Integrated Public Alert and Warning System (IPAWS), which brokers alerts from authorized originators to distribution channels including Wireless Emergency Alerts (WEA), the broadcast Emergency Alert System (EAS), and NOAA Weather Radio. IPAWS exchanges alert content using the Common Alerting Protocol (CAP) v1.2, enabling structured, multi-channel delivery and machine-readable metadata \cite{fema-ipaws-2025,oasis-cap-1.2}. Since 2018, successive FCC rulemakings have tightened WEA performance requirements: device-based geo\-targeting must match the target area with no more than approximately 0.1~mile overshoot beyond the polygon, and providers must meet transmission speed and logging requirements \cite{fcc-2018-geo,fcc-wea-2023-doc}. FEMA’s current implementation guidance emphasizes this geographic accuracy objective for WEA delivery, and industry materials highlight device-assisted geofencing in the WEA~3.0 architecture \cite{fema-wea-geo-2023,atis-0700041-summary}. Empirically, independent assessments demonstrate strong but nonuniform reach and latency. RAND/HSOAC’s national survey of the Oct.\ 4, 2023 nationwide test characterizes receipt, opt-in, and demographic patterns \cite{rand-wea-2023-test}, while McBride \emph{et~al.} measured median delivery latencies on the order of seconds and largely accurate geofences in ShakeAlert-supported trials \cite{mcbride-2023-wea-latency}. These results motivate client-side resilience—e.g., prefetching, caching, and offline fallback—to hedge against residual gaps from congestion, RF shadowing, or localized outages.

\subsection{Offline-First Applications}
Offline-first design patterns let safety-critical apps remain usable under partial connectivity. On the web, service workers and the Cache API enable background fetch, request interception, and robust fallbacks; platform guides document data modeling, consistency, and sync strategies for PWAs operating with intermittent networks \cite{webdev-offline-data-2022,webdev-service-workers-2021,whatwg-sw-2025}. On mobile, platform guidance formalizes offline-first architecture as a cross-cutting concern of the data layer (caching, conflict handling, and retries) \cite{android-offline-first-2025}. For durable client storage, Dexie.js provides typed, indexable stores over IndexedDB suitable for structured local databases and queryable caches used by PWAs \cite{dexie-docs-home}. Complementary “local-first” work articulates principles for apps that keep authoritative local state and synchronize opportunistically (often via CRDTs), informing our approach to conflict-free, eventually consistent alert archives and map layers \cite{kleppmann-2019-localfirst}. In emergency contexts, these patterns support prefetch of hazard layers, shelters, and guidance; durable storage of prior alerts for auditability; and continuity of core functions during network degradation.

\subsection{Caching Strategies for Emergency Systems}
Network-side caching can reduce tail latency and backhaul dependence during incident-driven traffic spikes. Surveys of mobile edge computing (MEC) detail cache placement and cooperation at the edge to improve hit rates and responsiveness for time-sensitive content \cite{mec-caching-survey-2023}. In Information-/Named-Data Networking (ICN/NDN), systematic surveys cover in-network caching strategies tuned to popularity, mobility, and energy constraints, including IoT deployments that resemble disrupted, ad hoc post-disaster networks \cite{icn-iot-caching-survey-2023}. Recent techniques explore learning-based placement (e.g., bandit/RL hybrids) and hybrid popularity/centrality policies to sustain performance under mobility and intermittent links \cite{cache-mab-2023,electronics-2024-koide-icanet}. Beyond hit ratio, “freshness” is a first-order requirement for real-time guidance; system-level treatments frame adaptive TTLs, invalidation, and priority refresh as design knobs that trade staleness against load and reach \cite{hotnets-2024-freshness}. AWARE adopts these lessons with priority-aware eviction and prefetch keyed to hazard severity, temporal sensitivity, and proximity.

\subsection{Location-Based Emergency Services}
Standards and policy now expect polygonal targeting with device-assisted geofencing in WEA, minimizing over-alerting while maintaining high coverage inside the alert area \cite{fcc-2018-geo,fcc-wea-2023-doc,fema-wea-geo-2023,atis-0700041-summary}. In parallel, the NWS Hazard Simplification program consolidates products and standardizes “What–Where–When–Impacts” phrasing to improve interpretability; Impact-Based Warnings (IBW) for flash floods add structured severity and impact cues intended to reduce alert fatigue and improve actionability \cite{nws-hazsimp-2023,nws-ffwea}. Methodologically, geofencing studies quantify precision/recall as a function of radius, environment, OS, and event type, informing practical buffer selection and distance-weighted ranking in location-aware filtering \cite{shevchenko-2023-geofencing}. These threads motivate our combination of device-level geofencing with cache priorities that elevate locally relevant, high-impact content during flood scenarios.

\subsection{Human and Cognitive Factors in Emergency Communication}
Decades of risk-communication research show that the efficacy of alerts depends on clarity, timing, trust, and cognitive load—not delivery alone. Classic work and subsequent syntheses emphasize concise, directive messages and pathways from warning receipt to protective action (e.g., the Protective Action Decision Model) \cite{mileti-1990-ornl6609,lindell-2012-padm,nasem-2018-alerts,cdc-cerc-2014}. During disasters, social support and perceived control correlate with better psychological outcomes; resilient communication systems can buffer stress by maintaining a sense of connection even asynchronously \cite{cohen-1985-socialsupport,norris-2008-resilience}. For interface design, trust and progressive disclosure support comprehension and compliance under stress \cite{paton-2008-warningresponse}. AWARE aligns with these principles by prioritizing terse, high-impact messages; surfacing nearby shelters and actionable guidance first; and retaining background data for audit and continuity when connectivity is degraded.

\section{System Architecture}

\subsection{AWARE EAS Framework Overview}
AWARE is implemented as a browser-hosted progressive web application (PWA) with four cooperating layers:

\begin{enumerate}
\item \textbf{UI \& Harness (React/TypeScript).} A Vite-bundled React shell mounts the simulation controls and results views. The harness selects a scenario (\texttt{urban}, \texttt{suburban}, \texttt{rural}), a cache policy (e.g., LRU or \texttt{PriorityFresh}), and a random seed, then drives the simulator to produce per-device samples and a summary metric vector.

\item \textbf{Simulation Core.} Deterministic modules model (i) network sectors with throughput/RTT/drop parameters, (ii) end devices with a pluggable cache policy, and (iii) alert workloads. The core exposes \texttt{runSim({scenario, policy, seed})}, which returns \texttt{{summary, samples}}. A fixed-step logical clock avoids wall-clock dependence; a Mulberry32 PRNG ensures reproducibility.

\item \textbf{Offline/Cache Layer (Service Worker).} A service worker intercepts requests and applies differentiated strategies: (i) \emph{network-first} for emergency endpoints (\texttt{/api/{alerts, emergency, shelters}}) with a dedicated \textit{alerts} cache; (ii) \emph{cache-first} for static assets; and (iii) \emph{stale-while-revalidate} for general API traffic. Successful emergency responses are stored with metadata (cached-at timestamp, priority hint) to enable audit and freshness management. Background Sync and Push handlers support deferred submission and high-priority notifications.

\item \textbf{Local Data Store (Dexie/IndexedDB).} A typed Dexie database persists alert reports, shelter inventories, and run metadata for analysis, export, and offline continuity. Object-store indexes enable time-bounded queries (e.g., “active alerts now”) and quick filtering by severity/urgency.
\end{enumerate}

\noindent\textbf{Execution flow.} On scenario start, the harness instantiates sectors and devices, then dispatches the alert sequence. Each device attempts a cache read; on miss, a sector transfer is simulated (throughput + RTT + drop). Devices record bytes, hits/reads, and first-receipt time to derive coverage, latency, and cache metrics. The run’s configuration, seed, and results are committed to Dexie for later export.

\subsection{Data Model}
We model three primary data types aligned with emergency operations and our simulator’s needs.

\subsubsection{Emergency Reports}
Each emergency report is a normalized representation of a CAP-like alert with spatial targeting and freshness controls:
\begin{itemize}
\item \texttt{id}: globally unique alert identifier.
\item \texttt{eventType}: e.g., \emph{FlashFloodWarning}, \emph{FloodAdvisory}.
\item \texttt{severity} $\in {\texttt{Moderate},\texttt{Severe},\texttt{Extreme}}$.
\item \texttt{urgency} $\in {\texttt{Expected},\texttt{Immediate}}$.
\item \texttt{certainty} (optional): \emph{Observed}/\emph{Likely}.
\item \texttt{polygon}: target area as coordinates (lon,lat) or GeoJSON.
\item \texttt{issuedAt}/\texttt{expiresAt}: epoch ms.
\item \texttt{headline}, \texttt{instruction}: terse, action-oriented text.
\item \texttt{sizeBytes}: payload bundle size (simulator parameter).
\item \texttt{geokey}: spatial key (e.g., geohash/tile) for coarse location filtering.
\end{itemize}

\subsubsection{Shelter Information}
Shelter entries provide nearby protective action options that can be cached and surfaced first:
\begin{itemize}
\item \texttt{id}, \texttt{name}, \texttt{address} (optional).
\item \texttt{coordinates}: \texttt{[lon,lat]}.
\item \texttt{capacity}: nominal capacity; \texttt{status} $\in {\texttt{open},\texttt{full},\texttt{closed}}$.
\item \texttt{updatedAt}: last verification timestamp.
\item \texttt{geokey}: spatial key for proximity queries.
\end{itemize}

\subsubsection{Metadata}
System and experiment metadata support reproducibility and offline continuity:
\begin{itemize}
\item \texttt{runs}: \texttt{(id, scenario, policy, seed, timestamp, metrics, samplesCount, notes, experimentName, fullResults)}.
\item \texttt{kvs} (key–value store): \texttt{(key, value)} for app/version/cache policy, last sync, and flags.
\end{itemize}

\subsection{Database Schema}
We implement a single Dexie database with four object stores: \texttt{reports}, \texttt{shelters}, \texttt{runs}, and \texttt{kvs}. Time and severity/urgency indexes accelerate “active and important” queries; \texttt{geokey} enables coarse spatial filtering without a heavy geospatial index.

\begin{lstlisting}[language=JavaScript, caption=AWARE EAS Database Schema Implementation]
import Dexie from "dexie";

// ---- Types (TS) shown for clarity; JS apps can omit ----
/** @typedef {{ id:string, eventType:string,

severity:'Moderate'|'Severe'|'Extreme',

urgency:'Expected'|'Immediate',

certainty?:string, polygon:string, // GeoJSON or JSON.stringify of [[lon,lat],...]

issuedAt:number, expiresAt:number,

headline?:string, instruction?:string,

sizeBytes?:number, geokey?:string }} Report */

/** @typedef {{ id:string, name:string, address?:string,

coordinates:[number,number], capacity?:number,

status:'open'|'full'|'closed', updatedAt:number,

geokey?:string }} Shelter */

/** @typedef {{ id:string, scenario:string, policy:string,

seed:string, timestamp:number,

metrics:any, samplesCount:number,

experimentName?:string, notes?:string,

fullResults?:any }} RunMeta */

/** @typedef {{ key:string, value:string }} KV */

export const db = new Dexie("awareDB");
db.version(1).stores({
// Index by issuedAt/expiresAt for "active now" queries;
// by severity/urgency for action-first ranking; by geokey for proximity.
reports: "id, issuedAt, expiresAt, severity, urgency, geokey, eventType",
// Coarse spatial key + status for nearby, open shelters first.
shelters: "id, geokey, status, updatedAt, name",
// Keep every run for reproducibility; timestamp index for recents.
runs: "id, timestamp, scenario, policy, seed, experimentName",
// Lightweight app KV (e.g., cachePolicy=PriorityFresh@v1).
kvs: "key"
});

// Convenience helpers (optional)
export async function putReports(list /* Report[] /) {
return db.table("reports").bulkPut(list);
}
export async function putShelters(list / Shelter[] /) {
return db.table("shelters").bulkPut(list);
}
export async function logRun(run / RunMeta */) {
return db.table("runs").put(run);
}
export async function setKV(key, value) {
return db.table("kvs").put({ key, value });
}
\end{lstlisting}

\paragraph{Query patterns.}
(1) \emph{Active alerts}: \texttt{issuedAt <= now < expiresAt} with secondary sort by \texttt{severity} and \texttt{urgency}. (2) \emph{Nearby content}: prefix-match \texttt{geokey} at decreasing precision (e.g., geohash 6$\rightarrow$5) for resilient proximity search offline. (3) \emph{Audit \& export}: select the latest \texttt{runs} by \texttt{timestamp} and join with summary metrics for figures and tables.

\paragraph{Why this layout?}
This schema keeps emergency reads $\mathcal{O}(\log n)$ via time indexes, avoids heavyweight spatial dependencies by using a coarse \texttt{geokey}, and preserves full experimental lineage for reproducibility. It also mirrors the simulator’s in-memory alert model (id, polygon, sizeBytes, issued/expire, urgency, severity), minimizing translation overhead between sim outputs and the persisted store.

\section{Smart Caching Algorithm}

\subsection{Cache Replacement Strategy}

We introduce \texttt{PriorityFresh}, a hybrid replacement strategy that extends Least Recently Used (LRU) by considering both temporal freshness and semantic priority of alerts. When the cache reaches capacity, items are evicted according to the following rule: 
\begin{itemize}
    \item Expired or stale entries are removed first.
    \item Among remaining items, those with the lowest composite priority score are evicted.
    \item If priorities tie, recency (LRU) is used as a tiebreaker.
\end{itemize}

\begin{algorithm}[h]
\caption{PriorityFresh Cache Replacement}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Cache $C$, new alert $a$, priority function $P(\cdot)$
\IF{$|C| < capacity$}
    \STATE Insert $a$ into $C$
\ELSE
    \STATE Identify $x \in C$ with lowest $P(x)$ (ties $\rightarrow$ LRU)
    \STATE Evict $x$
    \STATE Insert $a$
\ENDIF
\end{algorithmic}
\end{algorithm}

\subsection{Priority Calculation Framework}

Each alert is assigned a composite score:
\begin{equation}
    \text{Priority}(a) = w_1 \cdot S(a) + w_2 \cdot U(a) + w_3 \cdot F(a) + w_4 \cdot L(a)
\end{equation}
where:
\begin{align}
    S(a) &= \text{severity level (e.g., Severe = 2, Extreme = 3)} \\
    U(a) &= \text{urgency weight (Expected = 1, Immediate = 2)} \\
    F(a) &= \text{freshness score = $e^{-\lambda \cdot \Delta t}$, } \Delta t = \text{age of alert} \\
    L(a) &= \text{location relevance, 1 if inside polygon, else $e^{-\alpha d}$}
\end{align}

The weights $w_1, w_2, w_3, w_4$ are adaptively tuned during simulation runs. For instance, during high-congestion periods, $w_3$ (freshness) may be emphasized to prevent stale alerts, whereas under stable conditions, $w_1$ (severity) is prioritized.

\subsection{Location-Aware Filtering}

Before delivery, alerts are filtered by a distance-weighted relevance score:
\begin{equation}
    R(a,u) = \begin{cases}
        1 & \text{if user $u$ is inside $a$'s polygon} \\
        e^{-\beta \cdot d(a,u)} & \text{otherwise}
    \end{cases}
\end{equation}
where $d(a,u)$ is the haversine distance from user $u$ to alert polygon centroid. This ensures that nearby shelters and alerts remain cached even when outside strict polygons, providing resilience against geofence misalignments.

\begin{table}[h]
\centering
\caption{Priority Component Weights in AWARE}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Component} & \textbf{Symbol} & \textbf{Default Weight} & \textbf{Adaptation} \\ \midrule
Severity & $S(a)$ & $w_1 = 0.35$ & Higher in life-threatening floods \\
Urgency & $U(a)$ & $w_2 = 0.30$ & Boosted during active warnings \\
Freshness & $F(a)$ & $w_3 = 0.20$ & Raised under congestion \\
Location & $L(a)$ & $w_4 = 0.15$ & Boosted if user mobility is high \\
\bottomrule
\end{tabular}
\end{table}

\section{Implementation Details}

\subsection{Technology Stack}

The AWARE prototype is implemented entirely client-side as a \textbf{Progressive Web Application (PWA)}. The stack is:

\begin{itemize}
    \item \textbf{Frontend/UI:} React 18 with TypeScript, bundled via Vite. Components implement scenario selection, cache policy toggling, and visualization of results.
    \item \textbf{Simulation Core:} Plain TypeScript modules modeling devices, networks, and alert flows. Randomness is driven by Mulberry32 seeded PRNGs for reproducibility.
    \item \textbf{Offline Layer:} Service Worker scripts implementing network-first, cache-first, and stale-while-revalidate strategies. Cache metadata is extended with timestamps and priority hints.
    \item \textbf{Local Database:} Dexie.js (IndexedDB wrapper) stores alerts, shelters, and experimental runs. Indexed queries enable efficient filtering by severity, urgency, and geokey.
    \item \textbf{Build/Runtime:} Node.js (v18+) with npm for development, with \texttt{vite} for fast bundling and hot reloads.
\end{itemize}

\paragraph{Reproducibility.}
All simulation runs log their seed, configuration, and results into the Dexie database (\texttt{runs} table). Two RNG utilities are included: Mulberry32 for deterministic integer streams, and a utility generator (Box--Muller normals, exponential arrivals, shuffle/choice) for synthetic workloads. Each run can be exported to CSV for statistical analysis.

\subsection{Offline Detection and Fallback}

Connectivity detection is multi-layered:

\begin{itemize}
    \item \textbf{Navigator API:} \texttt{navigator.onLine} and \texttt{online/offline} events provide coarse network state.
    \item \textbf{Heartbeat Checks:} Periodic \texttt{fetch()} calls to \texttt{/api/ping} confirm backend reachability beyond WiFi presence.
    \item \textbf{Service Worker Hooks:} Failed \texttt{fetch} events are intercepted to trigger fallbacks.
\end{itemize}

\begin{lstlisting}[language=JavaScript, caption={Offline Detection System}]
window.addEventListener("offline", () => {
  console.warn("Device offline, switching to cache mode");
  db.table("kvs").put({ key:"status", value:"offline" });
});

window.addEventListener("online", () => {
  console.info("Back online, triggering sync");
  triggerBackgroundSync();
});
\end{lstlisting}

\paragraph{Fallback strategy.}
When offline is detected, the system:
\begin{enumerate}
    \item Switches alert fetches to \textbf{cache-only} mode.
    \item Surfaces cached shelters and ``last known'' instructions prominently in the UI.
    \item Queues outbound acknowledgments or reports for later Background Sync.
    \item Records offline duration and user interaction for evaluation (offline survival metric).
\end{enumerate}

\subsection{Data Synchronization}

The synchronization engine ensures eventual consistency once connectivity resumes.

\begin{itemize}
    \item \textbf{Background Sync API:} Pending actions (e.g., user acknowledgments) are registered via \texttt{serviceWorkerRegistration.sync.register()}.
    \item \textbf{Conflict Handling:} Alerts are keyed by globally unique \texttt{id}; late arrivals overwrite expired or duplicate entries. Shelters adopt ``last-updated wins'' semantics using \texttt{updatedAt}.
    \item \textbf{Batch Updates:} Upon reconnect, the service worker requests \texttt{/api/alerts} and \texttt{/api/shelters} with \texttt{If-Modified-Since} headers to minimize bandwidth.
    \item \textbf{Audit Trail:} All sync events are logged to the Dexie \texttt{runs} store, enabling replay of recovery phases in experiments.
\end{itemize}

\begin{lstlisting}[language=JavaScript, caption={Background Sync Handler}]
self.addEventListener("sync", event => {
  if (event.tag === "resync-alerts") {
    event.waitUntil(fetchAndCacheAlerts());
  }
});
\end{lstlisting}

\paragraph{Reproducibility.}
We fix random seeds per scenario and run (e.g., \{42, 123, 456, \dots\}) and log the full configuration alongside results in a Dexie-backed store (\texttt{runs(id, scenario, policy, seed, timestamp, metrics, samplesCount, notes, experimentName, fullResults)}). Two RNGs are provided: a string-seeded Mulberry32 for legacy modules and a utility generator (Box--Muller normals, exponential interarrival, shuffle/choice) for workload scheduling. Each experiment exports per-run CSV and an aggregate summary for statistical analysis.

\section{Experimental Evaluation}

\subsection{Experimental Setup}

\paragraph{Environment.}
Node~18+, Vite dev server, TypeScript~5. Build with \texttt{npm run build}; run \texttt{npm run dev}. The PWA shell (\texttt{index.html}, manifest) mounts the React app and invokes the harness; experiments are selected from preset configs and executed entirely client-side for reproducibility.

\subsubsection{Simulation Environment}
We run all experiments inside a browser-hosted PWA harness. A local “mock IPAWS” fixture under \texttt{/api/\{alerts, emergency, shelters\}} provides deterministic JSON responses for cold-start and offline tests. The simulation harness exposes four presets:

\begin{itemize}
  \item \textbf{Quick Baseline}: small population (1{,}000 devices), 30\,min duration, 3 fixed seeds.
  \item \textbf{Comprehensive}: publication matrix (2{,}500 devices), 45\,min, 5 seeds for significance.
  \item \textbf{Stress Test}: large population (5{,}000 devices) with extreme burst/duplicate rates.
  \item \textbf{Cache Policy Comparison}: focused A/B across selected scenarios, 10 seeds.
\end{itemize}

Alerts are generated by a Poisson process with optional time-bounded bursts; severity/urgency follow configurable categorical draws; duplicate ratio controls redundancy. Devices are sampled into urban/suburban/rural sectors and assigned initial connectivity; targeted disruptions and congestion are injected to emulate outages.

\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{Dataset Characteristics}

\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{Performance Testing Scenarios}

\begin{enumerate}
\item DUMMY
\end{enumerate}

\subsection{Performance Metrics}

\subsubsection{Primary Metrics (Quantitative)}
We evaluate AWARE against baseline caching and delivery schemes using reproducible, machine-logged metrics:

\begin{itemize}
    \item \textbf{Delivery Latency}: Median (P50) and tail (P90/P95) time for devices inside the alert polygon to receive an alert.
    \item \textbf{Coverage}: Proportion of in-polygon devices that successfully receive alerts within a fixed deadline (e.g., 15~s).
    \item \textbf{Overshoot / Undershoot}: Fraction of devices incorrectly alerted outside the target area versus missed inside the polygon.
    \item \textbf{Resilience Under Outage}: Success rate when $N\%$ of towers or backhaul capacity are degraded; backlog drain time when service is restored.
    \item \textbf{Cache Hit Rate}: Ratio of requests served from cache versus network.
    \item \textbf{Freshness Age}: Time delta between alert update and what users actually observe (mean and 95th percentile).
    \item \textbf{Stale-Read Rate}: Fraction of cases where users view outdated alerts.
    \item \textbf{Prefetch Yield}: Proportion of prefetched alerts that were subsequently required.
    \item \textbf{Bytes per Device}: Average network traffic per user, used as a bandwidth and energy proxy.
\end{itemize}

\subsubsection{Secondary Metrics (Qualitative Proxies)}
Because emergency communication effectiveness extends beyond raw throughput, we capture indicators aligned with trust, cognitive load, and user perception:

\begin{itemize}
    \item \textbf{Actionability-First Ratio}: Likelihood that the first notification surfaced to a user is urgent and actionable rather than noise.
    \item \textbf{Redundancy Index}: Count of duplicate alerts received per device, approximating alert fatigue.
    \item \textbf{Noise-to-Signal Ratio}: Balance of informational updates to urgent warnings.
    \item \textbf{Timeliness Consistency}: Variation in receipt times across devices; high jitter undermines trust.
    \item \textbf{Fairness}: Share of devices in the slowest delivery quantile, i.e., the ``last to know'' problem.
    \item \textbf{Offline Survival}: Duration that cached alerts remain usable without connectivity; proportion of devices maintaining functionality in fully disconnected states.
\end{itemize}

\subsubsection{Metrics Summary}
Table~\ref{tab:metrics} summarizes how each metric is measured and why it matters in flood contexts.

\begin{table}[ht]
\centering
\caption{Evaluation Metrics for AWARE}
\label{tab:metrics}
\begin{tabularx}{\linewidth}{@{}l c X@{}}
\toprule
\textbf{Metric} & \textbf{Type} & \textbf{Relevance to Flood Scenarios} \\ \midrule
Delivery latency & Quant. & Determines timeliness of protective action \\
Coverage & Quant. & Ensures all at-risk users are reached \\
Overshoot / undershoot & Quant. & Avoids false alarms while maximizing true coverage \\
Resilience under outage & Quant. & Captures robustness during network failure \\
Cache hit rate & Quant. & Improves efficiency during congestion \\
Freshness / staleness & Quant. & Ensures users receive current, not outdated, guidance \\
Bytes per device & Quant. & Proxy for bandwidth and energy savings under stress \\
Actionability-first & Qual. & Reduces confusion; boosts compliance \\
Redundancy index & Qual. & Limits cognitive overload under stress \\
Timeliness consistency & Qual. & Supports trust through delivery uniformity \\
Offline survival & Qual. & Guarantees continuity when connectivity is severed \\ 
\bottomrule
\end{tabularx}
\end{table}

\begin{table}[ht]
\centering
\caption{Harness outputs mapped to evaluation metrics}
\begin{tabular}{@{}l l@{}}
\toprule
Harness field & Paper metric \\ \midrule
\texttt{averageLatency} & Delivery latency (P50/P95 proxy) \\
\texttt{deliveryRatio} & Coverage (in-polygon receipt rate) \\
\texttt{cacheHitRatio} & Cache hit rate \\
\texttt{alertsDropped} & Resilience under outage (failures) \\
\texttt{duplicatesFiltered} & Redundancy index (lower is better) \\
\texttt{finalConnectivity.*} & Outage state distribution / fairness \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Results and Analysis}

\subsubsection{Availability Performance}

\begin{table}[ht]
\centering
\caption{System Availability Performance}
\begin{tabular}{@{}lccc@{}}
\end{tabular}
\end{table}

Key findings include:
\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{Efficiency and Optimization Results}

\begin{table}[ht]
\centering
\caption{Performance Comparison with Traditional Systems}
\begin{tabular}{@{}lccc@{}}
\end{tabular}
\end{table}

\subsubsection{Storage and Resource Optimization}
\begin{itemize}
\item DUMMY
\end{itemize}

\section{Discussion and Future Work}

A distinctive contribution of AWARE is the incorporation of human-centered evaluation metrics. By tracking actionability-first ratio, redundancy index, and offline survival alongside classical measures such as latency and hit rate, AWARE bridges the gap between raw network performance and real-world usability. This perspective shows that resilience in flood communication is not only about keeping data moving, but also about reducing confusion, lowering cognitive load, and sustaining trust in the system under prolonged stress. Such findings suggest implications for policy and standards, where evaluation frameworks could expand beyond delivery speed to include user-centered reliability and psychological safety.

\subsection{System Advantages and Impact}

\subsubsection{Resilience and Reliability}
\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{Performance and User Experience}
\begin{itemize}
\item DUMMY
\end{itemize}

\subsection{Current Limitations and Challenges}

\subsubsection{Technical Constraints}
\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{Operational Considerations}
\begin{itemize}
\item DUMMY
\end{itemize}

\subsection{Future Research Directions}

\subsubsection{Advanced Intelligence and Prediction}
\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{Network Architecture Evolution}
\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{Enhanced User Interaction}
\begin{itemize}
\item DUMMY
\end{itemize}

\subsubsection{System Integration and Standardization}
\begin{itemize}
\item DUMMY
\end{itemize}

\section{Conclusion}

\section*{Acknowledgments}

\textit{This research was conducted in compliance with institutional review board guidelines and emergency management best practices. No personal or sensitive data was used in the empirical process.}

% Inline bibliography to avoid external file issues
\begin{thebibliography}{99}

\bibitem{fema-ipaws-2025}
FEMA, ``Integrated Public Alert and Warning System (IPAWS),'' program overview, accessed Aug.\ 20, 2025. Available: \url{https://www.fema.gov/emergency-managers/practitioners/integrated-public-alert-warning-system}
% FEMA IPAWS overview (official). Verified. 

\bibitem{oasis-cap-1.2}
OASIS, ``Common Alerting Protocol (CAP) Version 1.2,'' OASIS Standard, Jul.\ 1, 2010. Available: \url{https://docs.oasis-open.org/emergency/cap/v1.2/CAP-v1.2-os.html}

\bibitem{fcc-2018-geo}
Federal Communications Commission, ``Wireless Emergency Alerts; Emergency Alert System,'' \emph{Federal Register}, 83(40), Feb.\ 28, 2018. (Defines matching the target area with no more than 0.1\,mile overshoot.) Available: \url{https://www.federalregister.gov/documents/2018/02/28/2018-03990/wireless-emergency-alerts-emergency-alert-system}

\bibitem{fcc-wea-2023-doc}
Federal Communications Commission, ``Wireless Emergency Alerts; Emergency Alert System,'' \emph{Federal Register}, 88(118), pp.\ 40166--40188, Jun.\ 21, 2023. (Codifies 0.1\,mile accuracy, transmission speed requirements.) Available: \url{https://www.federalregister.gov/documents/2023/06/21/2023-12725/wireless-emergency-alerts-emergency-alert-system}

\bibitem{fcc-wea-factsheet-2025}
Federal Communications Commission, ``Wireless Emergency Alerts (WEA) — Consumer Guide,'' accessed Aug.\ 20, 2025. Available: \url{https://www.fcc.gov/consumers/guides/wireless-emergency-alerts}. (Alt. PDF: \url{https://www.fcc.gov/sites/default/files/wireless_emergency_alerts_wea.pdf})

\bibitem{atis-0700041-summary}
ATIS, ``Wireless Emergency Alerts (WEA),'' program page noting WEA~3.0 device-based geofencing and 0.1\,mile accuracy, May 2019--present. Available: \url{https://atis.org/wireless-emergency-alerts/}

\bibitem{fema-wea-geo-2023}
FEMA, ``Geographic Accuracy of Wireless Emergency Alerts (WEAs),'' Feb.\ 22, 2023. Available: \url{https://www.fema.gov/emergency-managers/practitioners/integrated-public-alert-warning-system/public/wireless-emergency-alerts/geographic-accuracy-wea}

\bibitem{rand-wea-2023-test}
A.\ M.\ Parker \emph{et al.}, ``Assessing Public Reach of the 2023 National Test of the Wireless Emergency Alerts (WEA) System: Results of a National Survey,'' RAND/HSOAC Research Report RR-A2451-1, 2024. Available: \url{https://www.rand.org/pubs/research_reports/RRA2451-1.html}

\bibitem{mcbride-2023-wea-latency}
S.\ K.\ McBride, R.\ Allen, S.\ Baltay, \emph{et al.}, ``Latency and geofence testing of Wireless Emergency Alerts for ShakeAlert,'' \emph{Safety Science}, vol.\ 157, 2023, Art.\ 105999. doi:\,10.1016/j.ssci.2022.105999

\bibitem{webdev-offline-data-2022}
web.dev (Google), ``Offline data (Learn PWA),'' Jan.\ 2022. Available: \url{https://web.dev/learn/pwa/offline-data}

\bibitem{webdev-service-workers-2021}
web.dev (Google), ``Service workers (Learn PWA),'' Dec.\ 2021. Available: \url{https://web.dev/learn/pwa/service-workers}

\bibitem{webdev-offline-cookbook-2014}
J.\ Archibald, ``The Offline Cookbook,'' Dec.\ 2014 (living article). Available: \url{https://jakearchibald.com/2014/offline-cookbook/}

\bibitem{whatwg-sw-2025}
WHATWG, ``Service Workers Living Standard,'' accessed Aug.\ 20, 2025. Available: \url{https://html.spec.whatwg.org/multipage/workers.html#service-workers}

\bibitem{android-offline-first-2025}
Android Developers, ``Build an offline-first app (Architecture),'' documentation, 2025. Available: \url{https://developer.android.com/topic/architecture/data-layer/offline-first}

\bibitem{dexie-docs-home}
Dexie.js, ``Docs \& API,'' 2024--2025. Available: \url{https://dexie.org/docs/}

\bibitem{kleppmann-2019-localfirst}
M.\ Kleppmann, A.\ Wiggins, N.\ Zeldovich, ``Local-First Software: You Own Your Data, in spite of the Cloud,'' \emph{Onward! 2019}, pp.\ 154--178. doi:\,10.1145/3359591.3359737

\bibitem{mec-caching-survey-2023}
T.\ V.\ Nguyen, A.\ T.\ Tran, N.\ N.\ Dao, H.\ Moon, S.\ Cho, ``Information fusion on delivery: A survey on the roles of mobile edge caching systems,'' \emph{Information Fusion}, vol.\ 89, pp.\ 486--509, Jan.\ 2023. doi:\,10.1016/j.inffus.2022.08.029

\bibitem{icn-iot-caching-survey-2023}
C.\ N.\ Pruthvi, H.\ S.\ Vimala, J.\ Shreyas, ``A systematic survey on content caching in ICN and ICN-IoT: Challenges, approaches and strategies,'' \emph{Computer Networks}, vol.\ 233, 2023, Art.\ 109896. doi:\,10.1016/j.comnet.2023.109896

\bibitem{cache-mab-2023}
S.\ M.\ A.\ Iqbal, M.\ Asaduzzaman, ``Cache-MAB: A reinforcement learning–based hybrid caching scheme in Named Data Networks,'' \emph{Future Generation Computer Systems}, vol.\ 147, pp.\ 163--178, 2023. doi:\,10.1016/j.future.2023.04.032

\bibitem{electronics-2024-koide-icanet}
M.\ Koide, Y.\ Ohira, Y.\ Hirota, ``Caching for Information-Centric Ad Hoc Networks using Popularity and Node Centrality,'' \emph{Electronics}, vol.\ 13, no.\ 11, 2024, Art.\ 2213. doi:\,10.3390/electronics13112213

\bibitem{hotnets-2024-freshness}
Z.\ Mao, R.\ Iyer, S.\ Shenker, I.\ Stoica, ``Revisiting Cache Freshness for Emerging Real-Time Applications,'' in \emph{Proc.\ ACM HotNets 2024}. doi:\,10.1145/3696348.3696858

\bibitem{nws-hazsimp-2023}
NOAA/National Weather Service, ``Hazard Simplification Project,'' project page, accessed Aug.\ 20, 2025. Available: \url{https://www.weather.gov/hazardsimplification/}

\bibitem{nws-ffwea}
NOAA/NWS, ``Impact-Based Flash Flood Warnings (IBW) — Fact Sheet,'' Aug.\ 2019. Available: \url{https://www.weather.gov/media/wrn/FFW-IBW-factsheet.pdf}

\bibitem{shevchenko-2023-geofencing}
V.\ Shevchenko, M.\ Rabinovich, A.\ Shoval, \emph{et al.}, ``Geofencing in location-based behavioral research,'' \emph{Behavior Research Methods}, 2024. doi:\,10.3758/s13428-024-02440-3

\bibitem{mileti-1990-ornl6609}
D.\ S.\ Mileti, J.\ H.\ Sorensen, ``Communication of Emergency Public Warnings: A Social Science Perspective and State-of-the-Art Assessment,'' Oak Ridge National Laboratory Report ORNL-6609, Aug.\ 1990. doi:\,10.2172/6137387

\bibitem{cohen-1985-socialsupport}
S.\ Cohen, T.\ A.\ Wills, ``Stress, social support, and the buffering hypothesis,'' \emph{Psychological Bulletin}, vol.\ 98, no.\ 2, pp.\ 310--357, 1985.

\bibitem{norris-2008-resilience}
F.\ H.\ Norris, S.\ P.\ Stevens, B.\ Pfefferbaum, K.\ F.\ Wyche, R.\ L.\ Pfefferbaum, ``Community Resilience as a Metaphor, Theory, Set of Capacities, and Strategy for Disaster Readiness,'' \emph{American Journal of Community Psychology}, vol.\ 41, pp.\ 127--150, 2008. doi:\,10.1007/s10464-007-9156-6

\bibitem{paton-2008-warningresponse}
D.\ Paton, ``Risk communication and natural hazard mitigation: How trust influences its effectiveness,'' \emph{International Journal of Global Environmental Issues}, vol.\ 8, nos.\ 1--2, pp.\ 2--16, 2008. doi:\,10.1504/IJGENVI.2008.017256

\bibitem{nasem-2018-alerts}
National Academies of Sciences, Engineering, and Medicine, ``Emergency Alert and Warning Systems: Current Knowledge and Future Research Needs,'' Washington, DC: The National Academies Press, 2018. doi:\,10.17226/24935

\bibitem{cdc-cerc-2014}
CDC, ``Crisis and Emergency Risk Communication (CERC) Manual,'' 2014 (and updates). Available: \url{https://emergency.cdc.gov/cerc/manual/index.asp}

\bibitem{lindell-2012-padm}
M.\ K.\ Lindell, R.\ W.\ Perry, ``The Protective Action Decision Model: Theoretical Modifications and Additional Evidence,'' \emph{Risk Analysis}, vol.\ 32, no.\ 4, pp.\ 616--632, 2012. doi:\,10.1111/j.1539-6924.2011.01647.x

\end{thebibliography}

\balance
\end{document}
